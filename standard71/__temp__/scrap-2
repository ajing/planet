https://discuss.pytorch.org/t/saving-and-loading-a-model-in-pytorch/2610/2

https://github.com/pytorch/examples/blob/master/imagenet/main.py







/opt/anaconda3/bin/python3.6 /root/share/project/pytorch/build/satndard-7/train-forest-0.py
train-forest-0.py: calling main function ...

--- [START 2017-05-29 14:27:51] ----------------------------------------------------------------

** some experiment setting **
	SEED    = 123
	file    = /root/share/project/pytorch/build/satndard-7/train-forest-0.py
	out_dir = /root/share/project/pytorch/results/kaggle-forest/resnet34-40479-256-jpg-fixed-0

** dataset setting **
	(height,width)    = (256, 256)
	in_channels       = 3
	train_dataset.split = train-40479
	train_dataset.num = 40479
	test_dataset.split = valid-8000
	test_dataset.num  = 8000
	batch_size        = 96
	train_loader.sampler = <torch.utils.data.sampler.RandomSampler object at 0x7ffa911a1940>
	test_loader.sampler  = <torch.utils.data.sampler.SequentialSampler object at 0x7ffa90fa8780>

** net setting **
<class 'net.model.resnet.ResNet'>

    def __init__(self, block, layers, num_classes=1000):
        self.inplanes = 64
        super(ResNet, self).__init__()
        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,
                               bias=False)
        self.bn1 = nn.BatchNorm2d(64)
        self.relu = nn.ReLU(inplace=True)
        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)
        self.layer1 = self._make_layer(block, 64, layers[0])
        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)
        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)
        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)

        #self.pool = nn.AvgPool2d(kernel_size=7)
        self.pool = nn.AdaptiveAvgPool2d(1)
        #self.pool = nn.AdaptiveMaxPool2d(1)
        self.fc = nn.Linear(512 * block.expansion, num_classes)

        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels
                m.weight.data.normal_(0, math.sqrt(2. / n))
            elif isinstance(m, nn.BatchNorm2d):
                m.weight.data.fill_(1)
                m.bias.data.zero_()

    def forward(self, x):
        x1  = self.conv1(x)
        x2  = self.bn1(x1)
        x3  = self.relu(x2)
        x4  = self.maxpool(x3)

        x5  = self.layer1(x4)
        x6  = self.layer2(x5)
        x7  = self.layer3(x6)
        x8  = self.layer4(x7)

        ## x8  = F.dropout(x8,p=0.5,training=self.training)
        x9  = self.pool(x8)
        x10 = x9.view(x9.size(0), -1)
        x11 = self.fc(x10)

        logit = x11
        prob = F.sigmoid(logit)

        return logit,prob


** start training here! **
 optimizer=<torch.optim.sgd.SGD object at 0x7ff326e74eb8>
 epoch   iter   rate  |  smooth_loss   |  train_loss  (acc)  |  valid_loss  (acc)  | min
----------------------------------------------------------------------------------------
  1.0     421    0.1000   |  0.155  | 0.162  0.838 | 0.165  0.835  |  2.2 min
  2.0     421    0.1000   |  0.133  | 0.128  0.877 | 0.211  0.808  |  2.3 min
  3.0     421    0.1000   |  0.134  | 0.117  0.900 | 0.189  0.818  |  2.2 min
  4.0     421    0.1000   |  0.117  | 0.097  0.920 | 0.281  0.754  |  2.2 min
  5.0     421    0.1000   |  0.122  | 0.105  0.904 | 0.242  0.783  |  2.2 min
  6.0     421    0.1000   |  0.117  | 0.130  0.888 | 0.132  0.878  |  2.2 min
  7.0     421    0.1000   |  0.119  | 0.141  0.850 | 0.173  0.818  |  2.2 min
  8.0     421    0.1000   |  0.115  | 0.111  0.904 | 0.183  0.833  |  2.2 min
  9.0     421    0.1000   |  0.113  | 0.111  0.883 | 0.120  0.884  |  2.2 min
 10.0     421    0.1000   |  0.113  | 0.088  0.930 | 0.169  0.839  |  2.3 min
 11.0     421    0.0100   |  0.101  | 0.078  0.946 | 0.093  0.919  |  2.4 min
 12.0     421    0.0100   |  0.107  | 0.126  0.894 | 0.091  0.921  |  2.3 min
 13.0     421    0.0100   |  0.100  | 0.101  0.903 | 0.091  0.922  |  2.3 min
 14.0     421    0.0100   |  0.092  | 0.088  0.923 | 0.093  0.918  |  2.2 min
 15.0     421    0.0100   |  0.092  | 0.112  0.904 | 0.089  0.923  |  2.4 min
 16.0     421    0.0100   |  0.093  | 0.099  0.909 | 0.087  0.923  |  2.3 min
 17.0     421    0.0100   |  0.096  | 0.098  0.918 | 0.091  0.920  |  2.4 min
 18.0     421    0.0100   |  0.100  | 0.091  0.928 | 0.088  0.923  |  2.4 min
 19.0     421    0.0100   |  0.097  | 0.089  0.922 | 0.087  0.924  |  2.3 min
 20.0     421    0.0100   |  0.095  | 0.087  0.916 | 0.089  0.922  |  2.2 min
 21.0     421    0.0100   |  0.095  | 0.079  0.930 | 0.090  0.920  |  2.2 min
 22.0     421    0.0100   |  0.093  | 0.083  0.937 | 0.087  0.926  |  2.2 min
 23.0     421    0.0100   |  0.091  | 0.107  0.916 | 0.088  0.924  |  2.2 min
 24.0     421    0.0100   |  0.090  | 0.112  0.903 | 0.084  0.927  |  2.2 min
 25.0     421    0.0100   |  0.088  | 0.096  0.918 | 0.089  0.922  |  2.2 min
 26.0     421    0.0050   |  0.091  | 0.081  0.934 | 0.083  0.928  |  2.2 min
 27.0     421    0.0050   |  0.088  | 0.077  0.935 | 0.083  0.929  |  2.2 min
 28.0     421    0.0050   |  0.089  | 0.090  0.933 | 0.082  0.930  |  2.2 min
 29.0     421    0.0050   |  0.093  | 0.081  0.929 | 0.083  0.927  |  2.2 min
 29.7     300    0.0050   |  0.086  | 0.081  0.936 | ... Process Process-175:
Process Process-177:
Process Process-176:
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.6/multiprocessing/process.py", line 249, in _bootstrap
    self.run()
  File "/opt/anaconda3/lib/python3.6/multiprocessing/process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
  File "/opt/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 35, in _worker_loop
    r = index_queue.get()
  File "/opt/anaconda3/lib/python3.6/multiprocessing/queues.py", line 342, in get
    with self._rlock:
  File "/opt/anaconda3/lib/python3.6/multiprocessing/synchronize.py", line 96, in __enter__
    return self._semlock.__enter__()
KeyboardInterrupt
Traceback (most recent call last):
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.6/multiprocessing/process.py", line 249, in _bootstrap
    self.run()
  File "/opt/anaconda3/lib/python3.6/multiprocessing/process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
  File "/opt/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 41, in _worker_loop
    samples = collate_fn([dataset[i] for i in batch_indices])
  File "/opt/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 41, in <listcomp>
    samples = collate_fn([dataset[i] for i in batch_indices])
  File "/root/share/project/pytorch/build/satndard-7/net/dataset/kgforest.py", line 177, in __getitem__
    img = self.transform(img)
  File "/opt/anaconda3/lib/python3.6/site-packages/torchvision/transforms.py", line 29, in __call__
    img = t(img)
  File "/opt/anaconda3/lib/python3.6/site-packages/torchvision/transforms.py", line 184, in __call__
    return self.lambd(img)
  File "/root/share/project/pytorch/build/satndard-7/train-forest-0.py", line 364, in <lambda>
    transforms.Lambda(lambda x: img_to_tensor(x)),
  File "/root/share/project/pytorch/build/satndard-7/net/dataset/tool.py", line 69, in img_to_tensor
    img = (img-mean)/std
  File "/opt/anaconda3/lib/python3.6/multiprocessing/process.py", line 249, in _bootstrap
    self.run()
KeyboardInterrupt
  File "/opt/anaconda3/lib/python3.6/multiprocessing/process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
  File "/opt/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py", line 35, in _worker_loop
    r = index_queue.get()
  File "/opt/anaconda3/lib/python3.6/multiprocessing/queues.py", line 343, in get
    res = self._reader.recv_bytes()
  File "/opt/anaconda3/lib/python3.6/multiprocessing/connection.py", line 216, in recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/opt/anaconda3/lib/python3.6/multiprocessing/connection.py", line 407, in _recv_bytes
    buf = self._recv(4)
  File "/opt/anaconda3/lib/python3.6/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
Traceback (most recent call last):
  File "/root/share/project/pytorch/build/satndard-7/train-forest-0.py", line 951, in <module>
    do_training()
  File "/root/share/project/pytorch/build/satndard-7/train-forest-0.py", line 481, in do_training
    loss  = multi_criterion(logits, labels.cuda())
  File "/opt/anaconda3/lib/python3.6/site-packages/torch/_utils.py", line 65, in _cuda
    return new_type(self.size()).copy_(self, async)
KeyboardInterrupt

Process finished with exit code 137 (interrupted by signal 9: SIGKILL)




